{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache NeRF Model for Fast Rendering\n",
    "## Modified for Fern Scene\n",
    "\n",
    "This notebook extracts the trained NeRF model into cached data structures for 30 FPS real-time rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import mcubes\n",
    "import trimesh\n",
    "\n",
    "from models.rendering import *\n",
    "from models.nerf import *\n",
    "\n",
    "from datasets import dataset_dict\n",
    "\n",
    "from utils import load_ckpt\n",
    "import tqdm\n",
    "\n",
    "import os\n",
    "# Set GPU device (change if you have multiple GPUs)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # Use GPU 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Load Model and Data\n",
    "\n",
    "**IMPORTANT: Modify these paths for YOUR scene!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading scene: horns\n",
      "Dataset from: ..\\data\\nerf_llff_data\\horns\n",
      "Model from: ckpts\\horns\\epoch=4.ckpt\n",
      "H = 378, W = 504, focal = 421.10296470036104, near = 1.3333333333333333, far = 21.334730896952106\n",
      "example c2w:\n",
      "[[ 0.9840111   0.0366225  -0.17430131 -0.60779285]\n",
      " [-0.01882579  0.99453607  0.10268202  0.36733163]\n",
      " [ 0.17710941 -0.09775888  0.97932398  0.17471896]]\n",
      "[INFO] Built fastnerf: 8 x 256 | 4 x 128 | 8\n",
      "✓ Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# MODIFY THESE FOR YOUR SCENE\n",
    "###############################################################################\n",
    "\n",
    "# Image resolution (must match training!)\n",
    "img_wh = (504, 378)  # LLFF fern default resolution\n",
    "# If you trained with different resolution, change this!\n",
    "\n",
    "dataset_name = 'llff'  # We're using LLFF format\n",
    "\n",
    "scene_name = 'horns'  # Name for output files\n",
    "\n",
    "# Path to your fern dataset (only needs poses_bounds.npy, not images!)\n",
    "root_dir = r'..\\data\\nerf_llff_data\\horns'\n",
    "\n",
    "# Path to your TRAINED model\n",
    "ckpt_path = r'ckpts\\horns\\epoch=4.ckpt'  # Adjust epoch number if needed\n",
    "\n",
    "###############################################################################\n",
    "# END OF MODIFICATIONS\n",
    "###############################################################################\n",
    "\n",
    "print(f\"Loading scene: {scene_name}\")\n",
    "print(f\"Dataset from: {root_dir}\")\n",
    "print(f\"Model from: {ckpt_path}\")\n",
    "\n",
    "# Load dataset (only for metadata like scene bounds)\n",
    "kwargs = {'root_dir': root_dir,\n",
    "          'img_wh': img_wh}\n",
    "if dataset_name == 'llff':\n",
    "    kwargs['spheric_poses'] = True\n",
    "    kwargs['split'] = 'test'\n",
    "else:\n",
    "    kwargs['split'] = 'train'\n",
    "    \n",
    "chunk = 1024*32  # Batch size for processing\n",
    "dataset = dataset_dict[dataset_name](**kwargs)\n",
    "\n",
    "# Load the trained model\n",
    "embedding_xyz = Embedding(3, 10)\n",
    "embedding_dir = Embedding(3, 4)\n",
    "\n",
    "nerf_fine = NeRF()\n",
    "load_ckpt(nerf_fine, ckpt_path, model_name='nerf_fine')\n",
    "nerf_fine.cuda().eval()\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "print(\"✓ Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Find Scene Bounds (Trial and Error)\n",
    "\n",
    "**What this does:**\n",
    "- Tests different bounding box sizes to find where the object is\n",
    "- Start with conservative bounds, adjust if needed\n",
    "\n",
    "**For LLFF fern, these defaults should work well.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid resolution: 512^3 = 134,217,728 voxels\n",
      "Scene bounds: X[-1.2, 1.2], Y[-1.2, 1.2], Z[-1.2, 1.2]\n",
      "Processing 134,217,728 points...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:27<00:00, 146.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ UVW shape: (512, 512, 512, 24), dtype: float32\n",
      "✓ Sigma shape: (512, 512, 512, 1), dtype: float32\n",
      "✓ Sigma range: [0.00, 1900.45]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# STEP 2A: Calculate 3D Grid (UVWs and Sigma)\n",
    "###############################################################################\n",
    "\n",
    "# Resolution of the 3D grid\n",
    "# Start LOW (256-512) for testing, then increase (768-1024) for final quality\n",
    "N = 512  # Lower = faster but lower quality. For testing use 256-512.\n",
    "         # For final caching use 768-1024\n",
    "\n",
    "print(f\"Grid resolution: {N}^3 = {N**3:,} voxels\")\n",
    "\n",
    "###############################################################################\n",
    "# ADJUST THESE BOUNDS IF YOUR SCENE IS CUT OFF\n",
    "###############################################################################\n",
    "# These define the 3D bounding box around your scene\n",
    "# For LLFF fern, these defaults work well\n",
    "\n",
    "xmin, xmax = -1.2, 1.2  # left/right range\n",
    "ymin, ymax = -1.2, 1.2  # forward/backward range\n",
    "zmin, zmax = -1.2, 1.2  # up/down range\n",
    "\n",
    "print(f\"Scene bounds: X[{xmin}, {xmax}], Y[{ymin}, {ymax}], Z[{zmin}, {zmax}]\")\n",
    "\n",
    "# IMPORTANT: All ranges must have the same length!\n",
    "assert (xmax - xmin) == (ymax - ymin) == (zmax - zmin), \"Bounds must be cubic!\"\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# Create 3D grid of coordinates\n",
    "x = np.linspace(xmin, xmax, N, endpoint=False)\n",
    "y = np.linspace(ymin, ymax, N, endpoint=False)\n",
    "z = np.linspace(zmin, zmax, N, endpoint=False)\n",
    "xyz_ = torch.FloatTensor(np.stack(np.meshgrid(x, y, z), -1).reshape(-1, 3))\n",
    "dir_ = torch.zeros_like(xyz_)  # Direction doesn't matter for density\n",
    "\n",
    "print(f\"Processing {xyz_.shape[0]:,} points...\")\n",
    "\n",
    "# Extract cached data from the model\n",
    "with torch.no_grad():\n",
    "    B = xyz_.shape[0]\n",
    "    uvw, sigma = [], []\n",
    "    for i in tqdm.trange(0, B, chunk):\n",
    "        # Query the model at these 3D positions\n",
    "        xyz_embedded = embedding_xyz(xyz_[i:i+chunk].cuda())\n",
    "        dir_embedded = embedding_dir(dir_[i:i+chunk].cuda())\n",
    "        xyzdir_embedded = torch.cat([xyz_embedded, dir_embedded], 1)\n",
    "        \n",
    "        # Get the cached components\n",
    "        uvw_, beta_, sigma_ = nerf_fine(xyzdir_embedded, return_components=True)\n",
    "        uvw.append(uvw_.cpu())    # Color/appearance data\n",
    "        sigma.append(sigma_.cpu()) # Density (where stuff is)\n",
    "        \n",
    "    # Reshape to 3D grid\n",
    "    uvw = torch.cat(uvw, 0).numpy().astype(np.float32).reshape(N, N, N, -1)\n",
    "    sigma = torch.cat(sigma, 0).numpy().astype(np.float32).reshape(N, N, N, -1)\n",
    "\n",
    "sigma = np.maximum(sigma, 0)  # Ensure non-negative density\n",
    "\n",
    "print(f\"✓ UVW shape: {uvw.shape}, dtype: {uvw.dtype}\")\n",
    "print(f\"✓ Sigma shape: {sigma.shape}, dtype: {sigma.dtype}\")\n",
    "print(f\"✓ Sigma range: [{sigma.min():.2f}, {sigma.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: Save Sparse Cache (Memory Efficient)\n",
    "\n",
    "**What this does:**\n",
    "- Only saves voxels where something exists (sigma > threshold)\n",
    "- Saves memory and loading time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density threshold: 0\n",
      "Non-empty voxels: 34,083,785 / 134,217,728 (25.4%)\n",
      "Index map shape: (512, 512, 512)\n",
      "Sparse data shape: (34083785, 25)\n",
      "✓ Saved cache files:\n",
      "  - output/horns_inds_512_0.npy\n",
      "  - output/horns_uvws_512_0.npy\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Density threshold: voxels below this are considered empty\n",
    "###############################################################################\n",
    "sigma_thresh = 0  # Start with 0, increase if too much empty space is cached\n",
    "\n",
    "print(f\"Density threshold: {sigma_thresh}\")\n",
    "\n",
    "# Find non-empty voxels\n",
    "mask = (sigma[:, :, :, 0] > sigma_thresh)\n",
    "\n",
    "# Get coordinates of non-empty voxels\n",
    "coords = np.nonzero(mask)\n",
    "nnz = coords[0].shape[0]\n",
    "sparsity = nnz / np.prod(mask.shape)\n",
    "\n",
    "print(f\"Non-empty voxels: {nnz:,} / {np.prod(mask.shape):,} ({sparsity*100:.1f}%)\")\n",
    "\n",
    "# Create index mapping (for fast lookup during rendering)\n",
    "inds = -np.ones_like(mask, dtype=np.int32)\n",
    "inds[coords] = np.arange(nnz)\n",
    "\n",
    "# Extract data only for non-empty voxels\n",
    "uvws = np.concatenate([\n",
    "    uvw[coords],   # Color data\n",
    "    sigma[coords], # Density\n",
    "], axis=1).astype(np.float32)\n",
    "\n",
    "print(f\"Index map shape: {inds.shape}\")\n",
    "print(f\"Sparse data shape: {uvws.shape}\")\n",
    "\n",
    "# Save the cached data\n",
    "output_prefix = f'output/{scene_name}'\n",
    "np.save(f'{output_prefix}_inds_{N}_{sigma_thresh}.npy', inds)\n",
    "np.save(f'{output_prefix}_uvws_{N}_{sigma_thresh}.npy', uvws)\n",
    "\n",
    "print(f\"✓ Saved cache files:\")\n",
    "print(f\"  - {output_prefix}_inds_{N}_{sigma_thresh}.npy\")\n",
    "print(f\"  - {output_prefix}_uvws_{N}_{sigma_thresh}.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4: Cache Directional Data (Beta)\n",
    "\n",
    "**What this does:**\n",
    "- Stores how colors change based on viewing direction\n",
    "- Needed for realistic reflections and lighting effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching 200^3 = 8,000,000 view directions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:01<00:00, 134.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Beta shape: (200, 200, 200, 8), dtype: float32\n",
      "✓ Saved: output/horns_beta_200_cart.npy\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Cache directional appearance (cartesian version - more stable)\n",
    "###############################################################################\n",
    "\n",
    "M = 200  # Resolution for viewing directions\n",
    "         # Higher = better quality but slower. 200 is good balance.\n",
    "\n",
    "print(f\"Caching {M}^3 = {M**3:,} view directions...\")\n",
    "\n",
    "# Create grid of normalized direction vectors\n",
    "nx = np.linspace(-1, 1, M, endpoint=False)\n",
    "ny = np.linspace(-1, 1, M, endpoint=False)\n",
    "nz = np.linspace(-1, 1, M, endpoint=False)\n",
    "dir_ = np.stack(np.meshgrid(nx, ny, nz), -1).reshape(-1, 3)\n",
    "dir_ = dir_ / (np.linalg.norm(dir_, ord=2, axis=-1, keepdims=True) + 1e-6)\n",
    "dir_ = torch.FloatTensor(dir_).cuda()\n",
    "xyz_ = torch.zeros_like(dir_)  # Position doesn't matter for beta\n",
    "\n",
    "chunk = 1024*32\n",
    "\n",
    "with torch.no_grad():\n",
    "    B = dir_.shape[0]\n",
    "    beta = []\n",
    "    for i in tqdm.trange(0, B, chunk):\n",
    "        end = min(B, i+chunk)\n",
    "        xyz_embedded = embedding_xyz(xyz_[i:end].cuda())\n",
    "        dir_embedded = embedding_dir(dir_[i:end].cuda())\n",
    "        xyzdir_embedded = torch.cat([xyz_embedded, dir_embedded], 1)\n",
    "        \n",
    "        # Get directional components\n",
    "        uvw_, beta_, sigma_ = nerf_fine(xyzdir_embedded, return_components=True)\n",
    "        beta.append(beta_.cpu())\n",
    "        \n",
    "    beta = torch.cat(beta, 0).numpy().astype(np.float32).reshape(M, M, M, -1)\n",
    "\n",
    "print(f\"✓ Beta shape: {beta.shape}, dtype: {beta.dtype}\")\n",
    "\n",
    "# Save beta cache\n",
    "np.save(f'{output_prefix}_beta_{M}_cart.npy', beta)\n",
    "print(f\"✓ Saved: {output_prefix}_beta_{M}_cart.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5: Visualize 3D Mesh (Optional)\n",
    "\n",
    "**What this does:**\n",
    "- Extracts a 3D mesh from the density field\n",
    "- Lets you see if the scene bounds are correct\n",
    "\n",
    "**Skip this if you don't have trimesh/mcubes installed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mesh with threshold 20...\n",
      "✓ Mesh: 5279092 vertices, 10525106 faces\n",
      "Opening 3D viewer...\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Visualize the density as a 3D mesh\n",
    "###############################################################################\n",
    "\n",
    "# Try different thresholds to see the object clearly\n",
    "sigma_thresh_vis = 20  # Increase if too much noise, decrease if object is missing\n",
    "\n",
    "print(f\"Extracting mesh with threshold {sigma_thresh_vis}...\")\n",
    "\n",
    "try:\n",
    "    vertices, triangles = mcubes.marching_cubes(sigma[:, :, :, 0], sigma_thresh_vis)\n",
    "    \n",
    "    # Normalize vertices to [0, 1] range\n",
    "    vertices = vertices / N\n",
    "    \n",
    "    mesh = trimesh.Trimesh(vertices, triangles)\n",
    "    \n",
    "    print(f\"✓ Mesh: {len(vertices)} vertices, {len(triangles)} faces\")\n",
    "    print(\"Opening 3D viewer...\")\n",
    "    \n",
    "    mesh.show()  # Opens interactive 3D viewer\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not visualize mesh: {e}\")\n",
    "    print(\"Install mcubes and trimesh: pip install PyMCubes trimesh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!\n",
    "\n",
    "## Summary of Generated Files:\n",
    "\n",
    "```\n",
    "output/\n",
    "├── fern_inds_512_0.npy      ← Index map (which voxels are occupied)\n",
    "├── fern_uvws_512_0.npy      ← Color/density data for each voxel\n",
    "└── fern_beta_200_cart.npy   ← Directional appearance data\n",
    "```\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "1. **For higher quality**: Re-run with N=768 or N=1024\n",
    "2. **For interactive rendering**: Use these files with the Qt renderer\n",
    "3. **If scene is cut off**: Adjust xmin/xmax/ymin/ymax/zmin/zmax bounds\n",
    "\n",
    "## Using the Cache:\n",
    "\n",
    "The Qt renderer will load these files for 30 FPS real-time rendering!\n",
    "\n",
    "## File Sizes:\n",
    "- N=512: ~200-500 MB total\n",
    "- N=768: ~500 MB - 1 GB\n",
    "- N=1024: ~1-2 GB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
